{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras: The Python Deep Learning library\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khatwd2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width  target\n",
      "0           5.1          3.5           1.4          0.2       0\n",
      "1           4.9          3.0           1.4          0.2       0\n",
      "2           4.7          3.2           1.3          0.2       0\n",
      "3           4.6          3.1           1.5          0.2       0\n",
      "4           5.0          3.6           1.4          0.2       0\n"
     ]
    }
   ],
   "source": [
    "#get the iris data into pandas and clean up the column names into ones compatible with tensorflow\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "df.columns=[colname[:-4].strip().replace(' ','_') for colname in df.columns]\n",
    "df['target'] = pd.Series(iris.target)\n",
    "print(df.head())\n",
    "\n",
    "y=df['target']\n",
    "#keras requires one-hot encoded output\n",
    "y=pd.get_dummies(y)\n",
    "X=df.drop('target',axis=1)\n",
    "X= np.array(X)\n",
    "y=np.array(y)\n",
    "# split the data into trainning and test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "num_features=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Sequential API\n",
    "\n",
    "We still simply stack multiple dense layers together to create a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\khatwd2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\users\\khatwd2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 1.4910 - acc: 0.4000 - val_loss: 1.2765 - val_acc: 0.4667\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 133us/step - loss: 1.2254 - acc: 0.4750 - val_loss: 1.1070 - val_acc: 0.5333\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 142us/step - loss: 1.0751 - acc: 0.5417 - val_loss: 1.0044 - val_acc: 0.6000\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 142us/step - loss: 0.9930 - acc: 0.5333 - val_loss: 0.9461 - val_acc: 0.5667\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 183us/step - loss: 0.9433 - acc: 0.5833 - val_loss: 0.9134 - val_acc: 0.7667\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 150us/step - loss: 0.9150 - acc: 0.8250 - val_loss: 0.8892 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.8908 - acc: 0.8833 - val_loss: 0.8687 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 167us/step - loss: 0.8714 - acc: 0.8667 - val_loss: 0.8513 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 200us/step - loss: 0.8491 - acc: 0.8833 - val_loss: 0.8383 - val_acc: 0.9000\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 208us/step - loss: 0.8321 - acc: 0.8667 - val_loss: 0.8088 - val_acc: 0.9000\n",
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 892us/step - loss: 0.8095 - acc: 0.8667 - val_loss: 0.7952 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 142us/step - loss: 0.7907 - acc: 0.8250 - val_loss: 0.7691 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 142us/step - loss: 0.7726 - acc: 0.8333 - val_loss: 0.7471 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.7471 - acc: 0.8750 - val_loss: 0.7254 - val_acc: 0.9667\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 183us/step - loss: 0.7268 - acc: 0.8500 - val_loss: 0.7038 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 175us/step - loss: 0.6994 - acc: 0.8750 - val_loss: 0.6800 - val_acc: 0.9667\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 175us/step - loss: 0.6733 - acc: 0.8833 - val_loss: 0.6569 - val_acc: 0.9333\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.6452 - acc: 0.8583 - val_loss: 0.6231 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.6175 - acc: 0.8667 - val_loss: 0.5939 - val_acc: 0.9000\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 233us/step - loss: 0.5877 - acc: 0.8750 - val_loss: 0.5839 - val_acc: 0.8333\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 513\n",
      "Trainable params: 513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='relu', input_dim=num_features))\n",
    "model.add(Dense(units=20, activation='relu'))\n",
    "model.add(Dense(units=10, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#10 epoch isnt enough to obtain a good accuracy\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#save the model \n",
    "model.save('keras_partly_trained.h5')\n",
    "\n",
    "#load the model\n",
    "model = load_model('keras_partly_trained.h5')\n",
    "\n",
    "#keep training where we left off before\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#get summary of model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 167us/step\n",
      "[0.583909809589386, 0.8333333134651184]\n",
      "[[0.0889056  0.571777   0.33931732]\n",
      " [0.7434156  0.14440481 0.11217957]\n",
      " [0.03366585 0.4872718  0.47906235]\n",
      " [0.12053287 0.5022369  0.37723023]\n",
      " [0.09839346 0.6108736  0.29073298]\n",
      " [0.7182701  0.15545759 0.12627229]\n",
      " [0.21468848 0.47803926 0.3072723 ]\n",
      " [0.12131833 0.44295686 0.43572482]\n",
      " [0.10065459 0.5804552  0.31889024]\n",
      " [0.15961279 0.5422895  0.29809773]\n",
      " [0.10350662 0.44218698 0.45430636]\n",
      " [0.6542203  0.20061293 0.1451668 ]\n",
      " [0.7427429  0.14014848 0.11710869]\n",
      " [0.6528448  0.20468748 0.14246772]\n",
      " [0.7662282  0.12129451 0.11247732]\n",
      " [0.12516148 0.4838999  0.39093855]\n",
      " [0.05540251 0.40406165 0.5405358 ]\n",
      " [0.14050543 0.55789036 0.30160418]\n",
      " [0.10283836 0.51258194 0.38457963]\n",
      " [0.06160897 0.41436985 0.5240212 ]\n",
      " [0.6397836  0.2059724  0.15424404]\n",
      " [0.09998566 0.45028985 0.44972444]\n",
      " [0.6972236  0.16639324 0.13638319]\n",
      " [0.05963063 0.43112758 0.50924176]\n",
      " [0.05157655 0.526573   0.42185038]\n",
      " [0.10369509 0.427856   0.468449  ]\n",
      " [0.0504425  0.5193839  0.43017364]\n",
      " [0.05945098 0.40501305 0.535536  ]\n",
      " [0.66638875 0.18740289 0.14620836]\n",
      " [0.62529474 0.21963564 0.1550696 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 1,\n",
       "       0, 2, 1, 2, 1, 2, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets look at the test loss and accuracy \n",
    "# should match up with the output above\n",
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(loss_and_metrics)\n",
    "\n",
    "classes = model.predict(X_test, batch_size=128)\n",
    "print(classes)\n",
    "\n",
    "#get the index of the max probability for each row to get the predicted class\n",
    "classes.argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Functional API\n",
    "\n",
    "The Keras functional API is the way to go for defining complex models, such as multi-output models, directed acyclic graphs, or models with shared layers.\n",
    "\n",
    "### Re-implement Feed Forward nework with funcional API\n",
    "The Sequential model is probably a better choice to implement such a network, but it helps to start with something really simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.1622 - acc: 0.3750 - val_loss: 0.9403 - val_acc: 0.7000\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.9501 - acc: 0.6583 - val_loss: 0.8529 - val_acc: 0.7000\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 142us/step - loss: 0.8776 - acc: 0.6583 - val_loss: 0.8136 - val_acc: 0.7000\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.8306 - acc: 0.6583 - val_loss: 0.7883 - val_acc: 0.7000\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 200us/step - loss: 0.8087 - acc: 0.6583 - val_loss: 0.7638 - val_acc: 0.7000\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 192us/step - loss: 0.7982 - acc: 0.6583 - val_loss: 0.7483 - val_acc: 0.7000\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 225us/step - loss: 0.7659 - acc: 0.6583 - val_loss: 0.7269 - val_acc: 0.7000\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 158us/step - loss: 0.7465 - acc: 0.6583 - val_loss: 0.7112 - val_acc: 0.7000\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.7313 - acc: 0.6583 - val_loss: 0.6960 - val_acc: 0.7000\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 283us/step - loss: 0.7137 - acc: 0.6583 - val_loss: 0.6811 - val_acc: 0.7000\n",
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 992us/step - loss: 0.6966 - acc: 0.6583 - val_loss: 0.6680 - val_acc: 0.7000\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 167us/step - loss: 0.6899 - acc: 0.6583 - val_loss: 0.6656 - val_acc: 0.7000\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 250us/step - loss: 0.6693 - acc: 0.6667 - val_loss: 0.6383 - val_acc: 0.7000\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 250us/step - loss: 0.6620 - acc: 0.6667 - val_loss: 0.6297 - val_acc: 0.7333\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 208us/step - loss: 0.6370 - acc: 0.7250 - val_loss: 0.6116 - val_acc: 0.7667\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.6226 - acc: 0.7250 - val_loss: 0.5971 - val_acc: 0.7667\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 200us/step - loss: 0.6080 - acc: 0.7417 - val_loss: 0.5878 - val_acc: 0.7333\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 200us/step - loss: 0.5988 - acc: 0.7500 - val_loss: 0.5753 - val_acc: 0.7333\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.5836 - acc: 0.7250 - val_loss: 0.5605 - val_acc: 0.7667\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 167us/step - loss: 0.5677 - acc: 0.7583 - val_loss: 0.5463 - val_acc: 0.7667\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 513\n",
      "Trainable params: 513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "inputs = Input(shape=(4,))\n",
    "x = Dense(10,activation='relu')(inputs)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dense(units=10, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three hidden Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#10 epoch isnt enough to obtain a good accuracy\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#save the model \n",
    "model.save('keras_partly_trained.h5')\n",
    "\n",
    "#load the model\n",
    "model = load_model('keras_partly_trained.h5')\n",
    "\n",
    "#keep training where we left off before\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "#get summary of model architecture\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
